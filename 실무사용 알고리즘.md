### 실무사용 알고리즘 비교하기
 - 배열(수동 shift), vector, map, (구조=연결리스트 list) 등 사용하여 삽입,삭제,조회 로 시간측정
 - 여러 테스트를 할 때 어떤 코드가 적합한지 찾아보고 사용하기
#### 실제 테스트해 보기
<details> 
<summary>밴치마크 테스트</summary>
 
  ```ruby
// benchmark_realloc.cpp
// g++ -O2 -std=c++20 benchmark_realloc.cpp -o bench

#include <algorithm>
#include <chrono>
#include <cstdint>
#include <cstring>
#include <iomanip>
#include <iostream>
#include <list>
#include <map>
#include <memory>
#include <random>
#include <vector>

using Clock = std::chrono::high_resolution_clock;

struct Op {
    enum Type { Insert, Erase, Find } type;
    uint32_t pos_or_key;
    uint32_t value;
};

/* ================= ManualArray (with reallocation) ================= */
class ManualArray {
public:
    ManualArray() : cap_(0), size_(0) {}

    size_t size() const { return size_; }

    void insert(size_t pos, uint32_t v) {
        if (size_ >= cap_) grow();
        if (pos > size_) pos = size_;
        std::memmove(data_.get() + pos + 1,
            data_.get() + pos,
            (size_ - pos) * sizeof(uint32_t));
        data_[pos] = v;
        ++size_;
    }

    void erase(size_t pos) {
        if (size_ == 0) return;
        if (pos >= size_) pos = size_ - 1;
        std::memmove(data_.get() + pos,
            data_.get() + pos + 1,
            (size_ - pos - 1) * sizeof(uint32_t));
        --size_;
    }

    bool find_value(uint32_t v) const {
        for (size_t i = 0; i < size_; ++i)
            if (data_[i] == v) return true;
        return false;
    }

private:
    void grow() {
        size_t newCap = cap_ == 0 ? 8 : cap_ * 2;
        std::unique_ptr<uint32_t[]> newData(new uint32_t[newCap]);
        if (data_)
            std::memcpy(newData.get(), data_.get(),
                size_ * sizeof(uint32_t));
        data_.swap(newData);
        cap_ = newCap;
    }

    size_t cap_;
    size_t size_;
    std::unique_ptr<uint32_t[]> data_;
};

/* ================= helpers ================= */
template <typename T1, typename T2>
uint64_t ns(const T1& a, const T2& b)
{
    return std::chrono::duration_cast<std::chrono::nanoseconds>(b - a).count();
}

std::vector<Op> make_ops(size_t n, uint32_t seed = 1) {
    std::mt19937 rng(seed);
    std::uniform_int_distribution<int> pct(1, 100);
    std::uniform_int_distribution<uint32_t> val(1, 50000);

    std::vector<Op> ops;
    ops.reserve(n);

    uint32_t curSize = 10000;

    for (size_t i = 0; i < n; ++i) {
        Op op;
        int r = pct(rng);

        if (r <= 40) op.type = Op::Insert;
        else if (r <= 80) op.type = Op::Erase;
        else op.type = Op::Find;

        op.pos_or_key = curSize ? rng() % curSize : 0;
        op.value = val(rng);

        if (op.type == Op::Insert) ++curSize;
        if (op.type == Op::Erase && curSize) --curSize;

        ops.push_back(op);
    }
    return ops;
}

/* ================= Benchmarks ================= */
uint64_t bench_manual(const std::vector<Op>& ops) {
    ManualArray a;
    uint64_t found = 0;

    auto t0 = Clock::now();
    for (auto& op : ops) {
        if (op.type == Op::Insert) a.insert(op.pos_or_key, op.value);
        else if (op.type == Op::Erase) a.erase(op.pos_or_key);
        else found += a.find_value(op.value);
    }
    auto t1 = Clock::now();
    return ns(t0, t1);
}

uint64_t bench_vector(const std::vector<Op>& ops) {
    std::vector<uint32_t> v; // reserve 안 함 → 재할당 포함
    uint64_t found = 0;

    auto t0 = Clock::now();
    for (auto& op : ops) {
        if (op.type == Op::Insert) {
            size_t pos = v.empty() ? 0 : op.pos_or_key % v.size();
            v.insert(v.begin() + pos, op.value);
        }
        else if (op.type == Op::Erase && !v.empty()) {
            v.erase(v.begin() + (op.pos_or_key % v.size()));
        }
        else {
            found += std::find(v.begin(), v.end(), op.value) != v.end();
        }
    }
    auto t1 = Clock::now();
    return ns(t0, t1);
}

uint64_t bench_list(const std::vector<Op>& ops) {
    std::list<uint32_t> l;
    uint64_t found = 0;

    auto t0 = Clock::now();
    for (auto& op : ops) {
        if (op.type == Op::Insert) {
            auto it = l.begin();
            for (uint32_t i = 0; i < op.pos_or_key && it != l.end(); ++i) ++it;
            l.insert(it, op.value);
        }
        else if (op.type == Op::Erase && !l.empty()) {
            auto it = l.begin();
            for (uint32_t i = 0; i < op.pos_or_key && it != l.end(); ++i) ++it;
            if (it != l.end()) l.erase(it);
        }
        else {
            for (auto v : l)
                if (v == op.value) { ++found; break; }
        }
    }
    auto t1 = Clock::now();
    return ns(t0, t1);
}

uint64_t bench_map(const std::vector<Op>& ops) {
    std::map<uint32_t, uint32_t> m;
    uint64_t found = 0;

    auto t0 = Clock::now();
    for (auto& op : ops) {
        if (op.type == Op::Insert) m.emplace(op.pos_or_key, op.value);
        else if (op.type == Op::Erase) m.erase(op.pos_or_key);
        else found += m.find(op.pos_or_key) != m.end();
    }
    auto t1 = Clock::now();
    return ns(t0, t1);
}

/* ================= main ================= */
int main() {
    const size_t OPS = 20000;
    auto ops = make_ops(OPS);

    std::cout << "ops = " << OPS << "\n\n";
    std::cout << "ManualArray : " << bench_manual(ops) << " ns\n";
    std::cout << "vector      : " << bench_vector(ops) << " ns\n";
    std::cout << "list        : " << bench_list(ops) << " ns\n";
    std::cout << "map         : " << bench_map(ops) << " ns\n";
}

  ```
결과 값
ops = 20000

ManualArray : 1398900 ns
vector      : 9456700 ns
list        : 3396078000 ns
map         : 10500500 ns

</details>

<details> 
<summary>인덱스 형식으로 찾기를 할때</summary>
 
  ```ruby
// bench_index_vs_ptr.cpp
// g++ -O2 -std=c++17 bench_index_vs_ptr.cpp -o bench
// (MSVC) cl /O2 /std:c++17 bench_index_vs_ptr.cpp

#include <chrono>
#include <cstdint>
#include <iostream>
#include <random>
#include <unordered_map>
#include <vector>

struct CAchievementData {
    int32_t index;
    int32_t value;
};

static uint64_t now_ns() {
    using namespace std::chrono;
    return duration_cast<nanoseconds>(high_resolution_clock::now().time_since_epoch()).count();
}

template <typename Fn>
uint64_t time_ns(Fn&& fn) {
    uint64_t t0 = now_ns();
    fn();
    uint64_t t1 = now_ns();
    return t1 - t0;
}

// 최적화 방지용 sink
volatile int64_t g_sink = 0;

int main() {
    // =========================
    // 조절 파라미터
    // =========================
    const size_t N = 200000;          // 데이터 개수
    const size_t LOOKUPS = 5000000;   // 조회 횟수(랜덤 단건 조회)
    const uint32_t SEED = 42;

    // =========================
    // 1) vector 데이터 준비 (index는 1..N)
    // =========================
    std::vector<CAchievementData> rows;
    rows.reserve(N); // 벤치 공정성을 위해 미리 확보
    for (size_t i = 0; i < N; ++i) {
        CAchievementData d;
        d.index = static_cast<int32_t>(i + 1);
        d.value = static_cast<int32_t>((i * 2654435761u) ^ 0x9e3779b9u); // 대충 값 채움
        rows.push_back(d);
    }

    // 랜덤 조회할 키 목록 준비 (실제 workload에 가까운 형태)
    std::vector<int32_t> queryKeys;
    queryKeys.reserve(LOOKUPS);
    {
        std::mt19937 rng(SEED);
        std::uniform_int_distribution<int32_t> dist(1, static_cast<int32_t>(N));
        for (size_t i = 0; i < LOOKUPS; ++i) queryKeys.push_back(dist(rng));
    }

    // =========================
    // 2) A안: unordered_map<int, size_t> 빌드
    // =========================
    std::unordered_map<int32_t, size_t> mapIndexToPos;
    mapIndexToPos.reserve(N * 2); // 리해시 비용 줄이기(공정하게 동일하게도 적용 가능)
    uint64_t buildA = time_ns([&] {
        for (size_t pos = 0; pos < rows.size(); ++pos) {
            mapIndexToPos.emplace(rows[pos].index, pos);
        }
        });

    // =========================
    // 3) B안: unordered_map<int, CAchievementData*> 빌드
    //    (중요: rows가 더 커지지 않아 주소가 안 바뀌는 상태에서만)
    // =========================
    std::unordered_map<int32_t, CAchievementData*> mapIndexToPtr;
    mapIndexToPtr.reserve(N * 2);
    uint64_t buildB = time_ns([&] {
        for (size_t pos = 0; pos < rows.size(); ++pos) {
            mapIndexToPtr.emplace(rows[pos].index, &rows[pos]);
        }
        });

    // =========================
    // 4) 조회 벤치 (랜덤 단건 조회)
    // =========================
    uint64_t lookupA = 0;
    uint64_t lookupB = 0;

    // Warm-up (캐시/페이지 폴트 완화)
    {
        int64_t sum = 0;
        for (size_t i = 0; i < 10000 && i < queryKeys.size(); ++i) {
            auto it = mapIndexToPos.find(queryKeys[i]);
            if (it != mapIndexToPos.end()) sum += rows[it->second].value;
        }
        g_sink += sum;
    }

    lookupA = time_ns([&] {
        int64_t sum = 0;
        for (size_t i = 0; i < queryKeys.size(); ++i) {
            auto it = mapIndexToPos.find(queryKeys[i]);
            if (it != mapIndexToPos.end()) {
                sum += rows[it->second].value; // map->pos->vector
            }
        }
        g_sink += sum;
        });

    lookupB = time_ns([&] {
        int64_t sum = 0;
        for (size_t i = 0; i < queryKeys.size(); ++i) {
            auto it = mapIndexToPtr.find(queryKeys[i]);
            if (it != mapIndexToPtr.end()) {
                sum += it->second->value; // map->ptr
            }
        }
        g_sink += sum;
        });

    auto print = [&](const char* name, uint64_t ns_total, size_t ops) {
        double ns_per = static_cast<double>(ns_total) / static_cast<double>(ops);
        std::cout << name << ": " << ns_total << " ns  (" << ns_per << " ns/op)\n";
    };

    std::cout << "N=" << N << ", LOOKUPS=" << LOOKUPS << "\n";
    print("[Build] map<int,size_t>", buildA, N);
    print("[Build] map<int,ptr>   ", buildB, N);
    std::cout << "\n";
    print("[Lookup] map<int,size_t> -> vector[pos]", lookupA, LOOKUPS);
    print("[Lookup] map<int,ptr>   -> *ptr        ", lookupB, LOOKUPS);
    std::cout << "\n(sink=" << g_sink << ")\n";

    return 0;
}

  ```
결과 값
N=200000, LOOKUPS=5000000
[Build] map<int,size_t>: 155963200 ns  (779.816 ns/op)
[Build] map<int,ptr>   : 150254000 ns  (751.27 ns/op)

[Lookup] map<int,size_t> -> vector[pos]: 2146354000 ns  (429.271 ns/op)
[Lookup] map<int,ptr>   -> *ptr        : 2381262300 ns  (476.252 ns/op)

</details>

#### 실무에서 적합한지?
 - 실제로는 GPT가 추천하는 vector에 해당 위치를 파싱하는 방법이 속도는 제일 빠른것으로 나온다.
 - 그러나 ObjectPool을 사용하는 구조에서도 벡터의 크기가 늘어나는게 괜찮은지 테스트는 따로해봐야한다.
